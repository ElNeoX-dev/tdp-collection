---
# Hadoop version
hadoop_release: hadoop-3.1.1-TDP-0.1.0-SNAPSHOT
hadoop_dist_file: "{{ hadoop_release }}.tar.gz"

# Hadoop users and group
hdfs_user: hdfs
yarn_user: yarn
mapred_user: mapred
hadoop_group: hadoop

# Hadoop installation directory
hadoop_root_dir: /opt/tdp
hadoop_install_dir: "{{ hadoop_root_dir }}/hadoop"

# Hadoop configuration directories
hadoop_root_conf_dir: /etc/hadoop

# Hadoop HDFS/YARN directories
hadoop_hdfs_dir: /var/lib/hdfs
hadoop_yarn_dir: /var/lib/yarn

# Hadoop pid directories
hadoop_pid_dir: /run/hadoop
hadoop_hdfs_pid_dir: /run/hadoop/hdfs
hadoop_yarn_pid_dir: /run/hadoop/yarn

# ZKFC options
hdfs_zkfc_opts: ""

# Hadoop logging directory
hadoop_log_dir: /var/log/hadoop
hadoop_hdfs_log_dir: /var/log/hadoop/hdfs
hadoop_yarn_log_dir: /var/log/hadoop/yarn

# SSL Keystore and Truststore
hadoop_keystore_location: /etc/ssl/certs/keystore.jks
hadoop_keystore_password: Keystore123!
hadoop_truststore_location: /etc/ssl/certs/truststore.jks
hadoop_truststore_password: Truststore123!

ssl_server:
  ssl.server.keystore.location: "{{ hadoop_keystore_location }}"
  ssl.server.keystore.password: "{{ hadoop_keystore_password }}"
  # ssl.server.keystore.keypassword: "{{ hadoop_keystore_password }}"
  ssl.server.truststore.location: "{{ hadoop_truststore_location }}"
  ssl.server.truststore.password: "{{ hadoop_truststore_password }}"

ssl_client:
  # ssl.client.keystore.location: "{{ hadoop_keystore_location }}"
  # ssl.client.keystore.password: "{{ hadoop_keystore_password }}"
  # ssl.client.keystore.keypassword: "{{ hadoop_keystore_password }}"
  ssl.client.truststore.location: "{{ hadoop_truststore_location }}"
  ssl.client.truststore.password: "{{ hadoop_truststore_password }}"

# Properties
java_home: /usr/lib/jvm/jre-1.8.0-openjdk

hadoop_ha_zookeeper_quorum: |
  {{ groups['zk'] | 
     map('tosit.tdp.access_fqdn', hostvars) |
     map('regex_replace', '^(.*)$', '\1:2181') |
     list |
     join(',') }}
     
# core-site.xml - common
core_site:
  fs.defaultFS: "hdfs://mycluster"
  ha.zookeeper.quorum: "{{ hadoop_ha_zookeeper_quorum | trim }}"
  ha.zookeeper.acl: sasl:nn:rwcda
  hadoop.rpc.protection: authentication
  hadoop.security.authentication: kerberos
  hadoop.security.authorization: "true"
  hadoop.security.auth_to_local: |
    RULE:[2:$1/$2@$0]([ndj]n/.*@{{ realm }})s/.*/hdfs/
    RULE:[2:$1/$2@$0]([rn]m/.*@{{ realm }})s/.*/yarn/
    RULE:[2:$1/$2@$0](jhs/.*@{{ realm }})s/.*/mapred/
    RULE:[2:$1/$2@$0](hive/.*@{{ realm }})s/.*/hive/
    DEFAULT
  hadoop.proxyuser.hbase.groups: "*"
  hadoop.proxyuser.hbase.hosts: "*"
  hadoop.proxyuser.hdfs.groups: "*"
  hadoop.proxyuser.hdfs.hosts: "*"
  hadoop.proxyuser.hive.groups: "*"
  hadoop.proxyuser.hive.hosts: "*"
  hadoop.proxyuser.knox.groups: "*"
  hadoop.proxyuser.knox.hosts: "*"
  hadoop.proxyuser.knox.users: "*"
  hadoop.proxyuser.oozie.hosts: "*"
  hadoop.proxyuser.oozie.groups: "*"
  hadoop.proxyuser.phoenixqueryserver.hosts: "*"
  hadoop.proxyuser.phoenixqueryserver.groups: "*"
  # kerberos auth for the webuis
  # hadoop.http.authentication.type: kerberos
  # hadoop.http.authentication.kerberos.keytab: /etc/security/keytabs/spnego.service.keytab
  # hadoop.http.authentication.kerberos.principal: "HTTP/_HOST@{{ realm }}"
  # hadoop.http.filter.initializers: org.apache.hadoop.security.AuthenticationFilterInitializer
  hadoop.ssl.server.conf: ssl-server.xml
  hadoop.ssl.client.conf: ssl-client.xml

# hdfs-site.xml - common
# TODO: make a hdfs_site per service: nn, jn, dn
hdfs_site:
  dfs.replication: 1
  dfs.nameservices: mycluster
  dfs.ha.namenodes.mycluster: nn1,nn2
  dfs.ha.fencing.methods: shell(/bin/true)
  dfs.ha.automatic-failover.enabled: "true"
  dfs.http.policy: HTTPS_ONLY
  dfs.data.transfer.protection: authentication
  dfs.web.authentication.kerberos.keytab: /etc/security/keytabs/spnego.service.keytab
  dfs.web.authentication.kerberos.principal: "HTTP/_HOST@{{ realm }}"
  dfs.namenode.rpc-address.mycluster.nn1: "{{ groups['hdfs_nn'][0] | tosit.tdp.access_fqdn(hostvars) }}:8020"
  dfs.namenode.rpc-address.mycluster.nn2: "{{ groups['hdfs_nn'][1] | tosit.tdp.access_fqdn(hostvars) }}:8020"
  dfs.client.failover.proxy.provider.mycluster: org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
  dfs.journalnode.kerberos.principal: jn/_HOST@{{ realm }}
  dfs.journalnode.keytab.file: /etc/security/keytabs/jn.service.keytab
  dfs.block.access.token.enable: "true"

# TODO: make a yarn_site per service: rm, nm, ts
yarn_site:
  hadoop.zk.address: "{{ hadoop_ha_zookeeper_quorum | trim }}"
  yarn.application.classpath: "$HADOOP_CONF_DIR, {{ hadoop_install_dir }}/share/hadoop/common/*, {{ hadoop_install_dir }}/share/hadoop/common/lib/*, {{ hadoop_install_dir }}/share/hadoop/hdfs/*, {{ hadoop_install_dir }}/share/hadoop/hdfs/lib/*, {{ hadoop_install_dir }}/share/hadoop/yarn/*, {{ hadoop_install_dir }}/share/hadoop/yarn/lib/*"
  yarn.http.policy: HTTPS_ONLY
  yarn.log-aggregation-enable: "true"
  yarn.resourcemanager.ha.enabled: "true"
  yarn.resourcemanager.ha.rm-ids: "rm1,rm2"
  yarn.resourcemanager.cluster-id: "mycluster"
  yarn.resourcemanager.hostname.rm1: "{{ groups['yarn_rm'][0] | tosit.tdp.access_fqdn(hostvars) }}"
  yarn.resourcemanager.hostname.rm2: "{{ groups['yarn_rm'][1] | tosit.tdp.access_fqdn(hostvars) }}"
  yarn.resourcemanager.keytab: /etc/security/keytabs/rm.service.keytab
  yarn.resourcemanager.principal: "rm/_HOST@{{ realm }}"

